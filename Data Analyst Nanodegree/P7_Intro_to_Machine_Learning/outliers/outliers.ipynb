{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "### load up some practice data with outliers in it\n",
    "ages = pickle.load( open(\"practice_outliers_ages.pkl\", \"rb\") )\n",
    "net_worths = pickle.load( open(\"practice_outliers_net_worths.pkl\", \"rb\") )\n",
    "\n",
    "\n",
    "### ages and net_worths need to be reshaped into 2D numpy arrays\n",
    "### second argument of reshape command is a tuple of integers: (n_rows, n_columns)\n",
    "### by convention, n_rows is the number of data points\n",
    "### and n_columns is the number of features\n",
    "ages       = numpy.reshape( numpy.array(ages), (len(ages), 1))\n",
    "net_worths = numpy.reshape( numpy.array(net_worths), (len(net_worths), 1))\n",
    "from sklearn.cross_validation import train_test_split\n",
    "ages_train, ages_test, net_worths_train, net_worths_test = train_test_split(ages, net_worths, test_size=0.1, random_state=42)\n",
    "\n",
    "### fill in a regression here!  Name the regression object reg so that\n",
    "### the plotting code below works, and you can see what your regression looks like\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(ages_train, net_worths_train)\n",
    "\n",
    "\n",
    "try:\n",
    "    plt.plot(ages, reg.predict(ages), color=\"blue\")\n",
    "except NameError:\n",
    "    pass\n",
    "plt.scatter(ages, net_worths)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### identify and remove the most outlier-y points\n",
    "cleaned_data = []\n",
    "try:\n",
    "    predictions = reg.predict(ages_train)\n",
    "    cleaned_data = outlierCleaner( predictions, ages_train, net_worths_train )\n",
    "except NameError:\n",
    "    print(\"your regression object doesn't exist, or isn't name reg\")\n",
    "    print(\"can't make predictions to use in identifying outliers\")\n",
    "\n",
    "\n",
    "\n",
    "### only run this code if cleaned_data is returning data\n",
    "if len(cleaned_data) > 0:\n",
    "    ages, net_worths, errors = zip(*cleaned_data)\n",
    "    ages       = numpy.reshape( numpy.array(ages), (len(ages), 1))\n",
    "    net_worths = numpy.reshape( numpy.array(net_worths), (len(net_worths), 1))\n",
    "\n",
    "    ### refit your cleaned data!\n",
    "    try:\n",
    "        reg.fit(ages, net_worths)\n",
    "        plt.plot(ages, reg.predict(ages), color=\"blue\")\n",
    "    except NameError:\n",
    "        print(\"you don't seem to have regression imported/created,\")\n",
    "        print(\"   or else your regression object isn't named reg\")\n",
    "        print(\"   either way, only draw the scatter plot of the cleaned data\")\n",
    "    plt.scatter(ages, net_worths)\n",
    "    plt.xlabel(\"ages\")\n",
    "    plt.ylabel(\"net worths\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"outlierCleaner() is returning an empty list, no refitting to be done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope of regression with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"slope: \", reg.coef_)\n",
    "print(\"intercept: \", reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score of regression with outliers when it is applied to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train = reg.score(ages_test, net_worths_test)\n",
    "print(\"R^2 training data: \", sc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlierCleaner(predictions, ages, net_worths):\n",
    "    \"\"\"\n",
    "        Clean away the 10% of points that have the largest\n",
    "        residual errors (difference between the prediction\n",
    "        and the actual net worth).\n",
    "        Return a list of tuples named cleaned_data where \n",
    "        each tuple is of the form (age, net_worth, error).\n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_data = []\n",
    "\n",
    "    ### your code goes here\n",
    "    \n",
    "    # Define the 10% of train data i.e. 90 * 0.1 = 9\n",
    "    percentage = 0.1\n",
    "    limit = int(len(ages_train) * percentage)\n",
    "    \n",
    "    \"\"\"\n",
    "        zip() is a built-in python function that combines the entries in data containers, in order, as tuples\n",
    "        sorted is also a built-in python function that, as its names suggests, sorts lists.\n",
    "\n",
    "        If the list just contained integers or floats, then you would use:\n",
    "        \n",
    "        sorted(simpleList, reverse=True)\n",
    "        \n",
    "        which just sorts the list in reverse order.\n",
    "\n",
    "        If the list is a list of tuples, you can add an optional argument, a key,\n",
    "        to tell it which value in the tuple to sort by. In this case the key is:\n",
    "        \n",
    "        key=lambda x: x[2][0]\n",
    "        \n",
    "        which says sort by the first item, [0], in the third item x[2], of the tuple.\n",
    "\n",
    "        The reason for this is that the zipped list that you are sorting is a little more complicated\n",
    "        than just a tuple, it is a tuple of arrays (each array has only one item, hence the [0]).\n",
    "\n",
    "        x[2] is the third item in the tuple\n",
    "        x[2][0] is the first item in the third item in the tuple (given that there is only one item in that array,\n",
    "        it is both the first and only item)).\n",
    "\n",
    "        So, sorted() will look at that value, in each of the tuples, and sort the list, in reverse order,\n",
    "        based on those values.\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_data = []\n",
    "    predictions = reg.predict(ages_train)\n",
    "    errors = (net_worths_train - predictions)**2\n",
    "\n",
    "    cleaned_data = zip(ages_train, net_worths_train, errors)\n",
    "    cleaned_data = sorted(cleaned_data, key=lambda x:x[2][0], reverse=True)\n",
    "\n",
    "    return cleaned_data[limit:]\n",
    "    \n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(ages_train, net_worths_train)\n",
    "\n",
    "\n",
    "### identify and remove the most outlier-y points\n",
    "cleaned_data = []\n",
    "try:\n",
    "    predictions = reg.predict(ages_train)\n",
    "    cleaned_data = outlierCleaner( predictions, ages_train, net_worths_train )\n",
    "except NameError:\n",
    "    print(\"your regression object doesn't exist, or isn't name reg\")\n",
    "    print(\"can't make predictions to use in identifying outliers\")\n",
    "\n",
    "\n",
    "\n",
    "### only run this code if cleaned_data is returning data\n",
    "if len(cleaned_data) > 0:\n",
    "    ages, net_worths, errors = zip(*cleaned_data)\n",
    "    ages       = numpy.reshape( numpy.array(ages), (len(ages), 1))\n",
    "    net_worths = numpy.reshape( numpy.array(net_worths), (len(net_worths), 1))\n",
    "\n",
    "    ### refit your cleaned data!\n",
    "    try:\n",
    "        reg.fit(ages, net_worths)\n",
    "        plt.plot(ages, reg.predict(ages), color=\"blue\")\n",
    "    except NameError:\n",
    "        print(\"you don't seem to have regression imported/created,\")\n",
    "        print(\"   or else your regression object isn't named reg\")\n",
    "        print(\"   either way, only draw the scatter plot of the cleaned data\")\n",
    "    plt.scatter(ages, net_worths)\n",
    "    plt.xlabel(\"ages\")\n",
    "    plt.ylabel(\"net worths\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"outlierCleaner() is returning an empty list, no refitting to be done\")\n",
    "    \n",
    "print(\"slope: \", reg.coef_)\n",
    "print(\"intercept: \", reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score After Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train = reg.score(ages_test, net_worths_test)\n",
    "print(\"R^2 training data: \", sc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "\n",
    "### read in data dictionary, convert to numpy array\n",
    "data_dict = pickle.load( open(\"final_project_dataset.pkl\", \"rb\") )\n",
    "features = [\"salary\", \"bonus\"]\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "\n",
    "### your code below\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    matplotlib.pyplot.scatter( salary, bonus )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"salary\")\n",
    "matplotlib.pyplot.ylabel(\"bonus\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify The Biggest Enron Outlier\n",
    "* TOTAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Enron Outlier?\n",
    "* Take it out, it's a spreadsheet quirk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Enron Outlier. Any More Outliers?\n",
    "* Probably four more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, using no second argument, .pop() will throw a KeyError\n",
    "# if the key isn't found in the dictionary (it won't return None).\n",
    "# Sometimes, we don't want this behavior.\n",
    "# Instead of needing a try-except block to catch the error or\n",
    "# an if statement to make sure it isn't raised,\n",
    "# we can pass a second argument to .pop() which will be returned if the key isn't found.\n",
    "# So adding 0 returns 0 if the specified key isn't found.\n",
    "data_dict.pop('TOTAL', 0)\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "\n",
    "for point in data:\n",
    "    salary = point[0]\n",
    "    bonus = point[1]\n",
    "    matplotlib.pyplot.scatter( salary, bonus )\n",
    "\n",
    "matplotlib.pyplot.xlabel(\"salary\")\n",
    "matplotlib.pyplot.ylabel(\"bonus\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Two More Outliers\n",
    "We would argue that there’s 4 more outliers to investigate; let's look at a couple of them. Two people made bonuses of at least 5 million dollars, and a salary of over 1 million dollars; in other words, they made out like bandits. What are the names associated with those points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for employee in data_dict:\n",
    "    if (data_dict[employee][\"salary\"] != 'NaN') and (data_dict[employee][\"bonus\"] != 'NaN'):\n",
    "        if float(data_dict[employee][\"salary\"]) >1000000 and float(data_dict[employee][\"bonus\"])>5000000:\n",
    "            print(employee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove These Outliers?\n",
    "Would you guess that these are typos or weird spreadsheet lines that we should remove, or that there’s a meaningful reason why these points are different? In other words, should they be removed before we, say, try to build a POI identifier?\n",
    "* Leave them in, they are valid data points. They're two of Enron's biggest bosses, and definitely people of interest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
